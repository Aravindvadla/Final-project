{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ecc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629a6a7",
   "metadata": {},
   "source": [
    "\n",
    "# 4-wayAdditive DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec699369",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df = pd.read_csv('4-wayAdditive100feat.txt',delimiter='\\t')\n",
    "way_additive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42393c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2429f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "way_additive_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bdfdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data distribution\n",
    "plt.hist(way_additive_df[\"N0\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data\n",
    "print(way_additive_df[\"Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c20e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature relationships\n",
    "plt.scatter(way_additive_df[\"M0P1\"], way_additive_df[\"M1P2\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection\n",
    "plt.boxplot(way_additive_df[\"N0\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d31f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985734ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(data=way_additive_df, orient=\"h\", palette=\"Set2\")\n",
    "plt.title(\"Box Plots (or Violin Plots)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(way_additive_df[\"N52\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(way_additive_df[\"M2P3\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a58b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd627294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = way_additive_df.drop(columns=['Class'])  # Features\n",
    "y = way_additive_df['Class']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Display the shape of the resulting sets\n",
    "print(\"Training set - X:\", X_train.shape, \" y:\", y_train.shape)\n",
    "print(\"Testing set - X:\", X_test.shape, \" y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models to experiment with\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=10)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=10)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=10)),\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=10)),\n",
    "    (\"Support Vector Machine\", SVC(random_state=10)),\n",
    "]\n",
    "\n",
    "# Iterate through the models, train, and evaluate\n",
    "for model_name, model in models:\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Feature Importance Analysis\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # For tree-based models\n",
    "        feature_importance = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # For linear models (e.g., Logistic Regression)\n",
    "        feature_importance = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        # Model does not provide feature importance scores\n",
    "        print(f\"\\n{model_name} does not provide feature importance scores.\")\n",
    "        continue\n",
    "\n",
    "    # Create a DataFrame to display feature names and their importance scores\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance,\n",
    "    })\n",
    "\n",
    "    # Sort features by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualize Feature Importance\n",
    "    plt.figure(figsize=(16, 20))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'{model_name} - Feature Importance')\n",
    "    plt.show()\n",
    "\n",
    "    # Select top features based on importance scores\n",
    "    top_features = SelectFromModel(model, threshold='mean').fit(X_train, y_train).get_support()\n",
    "    print(f\"\\nTop Features for {model_name}:\\n\", X_train.columns[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Cross-Validation Accuracy: {cross_val_scores.mean():.4f} (+/- {cross_val_scores.std():.4f})\")\n",
    "\n",
    "    # Testing\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Additional evaluation metrics (classification report)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7e233",
   "metadata": {},
   "source": [
    "**Decision Tree**:\n",
    "Cross-Validation Accuracy: 89.62%\n",
    "Test Accuracy: 92.50%\n",
    "Balanced performance with good precision, recall, and F1-score for both classes.\n",
    "\n",
    "**Random Forest**:\n",
    "Cross-Validation Accuracy: 95.00%\n",
    "Test Accuracy: 97.50%\n",
    "Improved accuracy compared to the Decision Tree. Good precision, recall, and F1-score for both classes.\n",
    "\n",
    "**Gradient Boosting**:\n",
    "Cross-Validation Accuracy: 94.25%\n",
    "Test Accuracy: 97.50%\n",
    "Similar performance to Random Forest. High accuracy and balanced precision, recall, and F1-score for both classes.\n",
    "\n",
    "**Logistic Regression**:\n",
    "Cross-Validation Accuracy: 92.50%\n",
    "Test Accuracy: 96.50%\n",
    "Good performance with high precision, recall, and F1-score for both classes.\n",
    "\n",
    "**Support Vector Machine**:\n",
    "Cross-Validation Accuracy: 93.88%\n",
    "Test Accuracy: 98.00%\n",
    "Highest accuracy with balanced precision, recall, and F1-score for both classes.\n",
    "\n",
    "**General Observations**:\n",
    "All models perform well with high accuracy on the test set.\n",
    "Random Forest, Gradient Boosting, and Support Vector Machine show particularly high accuracy.\n",
    "Precision, recall, and F1-scores are balanced for both classes, indicating good model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5a536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a1574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94364ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c770e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052427e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3145f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e70563b5",
   "metadata": {},
   "source": [
    "# 2-wayEpi100feat DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayEpi1_df = pd.read_csv('2-wayEpi100feat.txt',delimiter='\\t')\n",
    "wayEpi1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495504ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayEpi1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayEpi1_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayEpi1_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayEpi1_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayEpi1_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fe144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data distribution\n",
    "plt.hist(wayEpi1_df[\"N10\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data\n",
    "print(wayEpi1_df[\"Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16cfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature relationships\n",
    "plt.scatter(wayEpi1_df[\"M0P1\"], way_additive_df[\"M1P2\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c82f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection\n",
    "plt.boxplot(way_additive_df[\"N52\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a722a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(data=wayEpi1_df, orient=\"h\", palette=\"Set2\")\n",
    "plt.title(\"Box Plots (or Violin Plots)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c40914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wayEpi1_df.drop(columns=['Class'])  # Features\n",
    "y = wayEpi1_df['Class']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12917211",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=10)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=10)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=10)),\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=10)),\n",
    "    (\"Support Vector Machine\", SVC(random_state=10)),\n",
    "]\n",
    "\n",
    "\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # For tree-based models\n",
    "        feature_importance = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # For linear models (e.g., Logistic Regression)\n",
    "        feature_importance = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        # Model does not provide feature importance scores\n",
    "        print(f\"\\n{model_name} does not provide feature importance scores.\")\n",
    "        continue\n",
    "\n",
    "    # Create a DataFrame to display feature names and their importance scores\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance,\n",
    "    })\n",
    "\n",
    "    # Sort features by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualize Feature Importance\n",
    "    plt.figure(figsize=(16, 20))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'{model_name} - Feature Importance')\n",
    "    plt.show()\n",
    "\n",
    "    # Select top features based on importance scores\n",
    "    top_features = SelectFromModel(model, threshold='mean').fit(X_train, y_train).get_support()\n",
    "    print(f\"\\nTop Features for {model_name}:\\n\", X_train.columns[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Cross-Validation Accuracy: {cross_val_scores.mean():.4f} (+/- {cross_val_scores.std():.4f})\")\n",
    "\n",
    "    # Testing\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Additional evaluation metrics (classification report)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85997e74",
   "metadata": {},
   "source": [
    "**Decision Tree**:\n",
    "Cross-Validation Accuracy: 51.75% (+/- 1.65)\n",
    "Test Accuracy: 50.00%\n",
    "Precision, recall, and F1-score are around 0.50 for both classes.\n",
    "\n",
    "**Random Forest:**\n",
    "Cross-Validation Accuracy: 52.63% (+/- 5.57)\n",
    "Test Accuracy: 55.00%\n",
    "Precision, recall, and F1-score are around 0.55 for both classes.\n",
    "\n",
    "**Gradient Boosting:**\n",
    "Cross-Validation Accuracy: 55.00% (+/- 4.87)\n",
    "Test Accuracy: 56.50%\n",
    "Precision, recall, and F1-score are around 0.56 for both classes.\n",
    "\n",
    "**Logistic Regression:**\n",
    "Cross-Validation Accuracy: 48.00% (+/- 4.86)\n",
    "Test Accuracy: 50.50%\n",
    "Precision, recall, and F1-score are around 0.50 for both classes.\n",
    "\n",
    "**Support Vector Machine:**\n",
    "Cross-Validation Accuracy: 49.38% (+/- 4.73)\n",
    "Test Accuracy: 48.50%\n",
    "Precision, recall, and F1-score are around 0.48 for both classes.\n",
    "\n",
    "**Observations:**\n",
    "None of the models are achieving high accuracy, and their performance is close to random guessing.\n",
    "The precision, recall, and F1-scores for both classes are not satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e8d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37a0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a363f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a012a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb1838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98f34f83",
   "metadata": {},
   "source": [
    "\n",
    "# 2Additive2-wayEpi100feat DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "additive2_wayEpi100feat_df = pd.read_csv('2Additive2-wayEpi100feat.txt',delimiter='\\t')\n",
    "additive2_wayEpi100feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b01dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "additive2_wayEpi100feat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ba66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "additive2_wayEpi100feat_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca76663",
   "metadata": {},
   "outputs": [],
   "source": [
    "additive2_wayEpi100feat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "additive2_wayEpi100feat_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data distribution\n",
    "plt.hist(additive2_wayEpi100feat_df[\"N40\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data\n",
    "print(additive2_wayEpi100feat_df[\"Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(data=additive2_wayEpi100feat_df, orient=\"h\", palette=\"Set2\")\n",
    "plt.title(\"Box Plots (or Violin Plots)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d0597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = additive2_wayEpi100feat_df.drop(columns=['Class'])  # Features\n",
    "y = additive2_wayEpi100feat_df['Class']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=10)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=10)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=10)),\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=10)),\n",
    "    (\"Support Vector Machine\", SVC(random_state=10)),\n",
    "]\n",
    "\n",
    "\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # For tree-based models\n",
    "        feature_importance = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # For linear models (e.g., Logistic Regression)\n",
    "        feature_importance = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        # Model does not provide feature importance scores\n",
    "        print(f\"\\n{model_name} does not provide feature importance scores.\")\n",
    "        continue\n",
    "\n",
    "    # Create a DataFrame to display feature names and their importance scores\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance,\n",
    "    })\n",
    "\n",
    "    # Sort features by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualize Feature Importance\n",
    "    plt.figure(figsize=(16, 20))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'{model_name} - Feature Importance')\n",
    "    plt.show()\n",
    "\n",
    "    # Select top features based on importance scores\n",
    "    top_features = SelectFromModel(model, threshold='mean').fit(X_train, y_train).get_support()\n",
    "    print(f\"\\nTop Features for {model_name}:\\n\", X_train.columns[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811f7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0352817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Cross-Validation Accuracy: {cross_val_scores.mean():.4f} (+/- {cross_val_scores.std():.4f})\")\n",
    "\n",
    "    # Testing\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Additional evaluation metrics (classification report)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a53e83",
   "metadata": {},
   "source": [
    "**Decision Tree**:\n",
    "Cross-Validation Accuracy: 51.38% (+/- 4.68)\n",
    "Test Accuracy: 58.50%\n",
    "Precision, recall, and F1-score are around 0.58 for both classes.\n",
    "\n",
    "**Random Forest**:\n",
    "Cross-Validation Accuracy: 55.12% (+/- 2.57)\n",
    "Test Accuracy: 51.00%\n",
    "Precision, recall, and F1-score are around 0.51 for both classes.\n",
    "\n",
    "**Gradient Boosting**:\n",
    "Cross-Validation Accuracy: 64.75% (+/- 4.60)\n",
    "Test Accuracy: 62.50%\n",
    "Precision, recall, and F1-score are around 0.62 for both classes.\n",
    "\n",
    "**Logistic Regression**:\n",
    "Cross-Validation Accuracy: 49.25% (+/- 3.05)\n",
    "Test Accuracy: 50.00%\n",
    "Precision, recall, and F1-score are around 0.50 for both classes.\n",
    "\n",
    "**Support Vector Machine**:\n",
    "Cross-Validation Accuracy: 51.88% (+/- 2.62)\n",
    "Test Accuracy: 48.00%\n",
    "Precision, recall, and F1-score are around 0.48 for both classes.\n",
    "\n",
    "**Observations**:\n",
    "Gradient Boosting seems to be performing relatively better compared to other models, with improved accuracy and F1-scores.\n",
    "Decision Tree also shows improvement, particularly in accuracy and precision.\n",
    "Random Forest, Logistic Regression, and Support Vector Machine have similar or slightly worse performance compared to the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3166b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7dd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d614c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526c0a97",
   "metadata": {},
   "source": [
    "# 4-wayHeterogeneous100feat DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wayHeterogeneous100feat\n",
    "wayHeterogeneous100feat_df = pd.read_csv('4-wayHeterogeneous100feat.txt',delimiter='\\t')\n",
    "wayHeterogeneous100feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2424fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayHeterogeneous100feat_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayHeterogeneous100feat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wayHeterogeneous100feat_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cee377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data distribution\n",
    "plt.hist(wayHeterogeneous100feat_df[\"N70\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0971f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550dc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(data=wayHeterogeneous100feat_df, orient=\"h\", palette=\"Set2\")\n",
    "plt.title(\"Box Plots (or Violin Plots)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86221fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683caadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wayHeterogeneous100feat_df.drop(columns=['Class'])  # Features\n",
    "y = wayHeterogeneous100feat_df['Class']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=10)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=10)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=10)),\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=10)),\n",
    "    (\"Support Vector Machine\", SVC(random_state=10)),\n",
    "]\n",
    "\n",
    "\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # For tree-based models\n",
    "        feature_importance = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # For linear models (e.g., Logistic Regression)\n",
    "        feature_importance = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        # Model does not provide feature importance scores\n",
    "        print(f\"\\n{model_name} does not provide feature importance scores.\")\n",
    "        continue\n",
    "\n",
    "    # Create a DataFrame to display feature names and their importance scores\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance,\n",
    "    })\n",
    "\n",
    "    # Sort features by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualize Feature Importance\n",
    "    plt.figure(figsize=(16, 20))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'{model_name} - Feature Importance')\n",
    "    plt.show()\n",
    "\n",
    "    # Select top features based on importance scores\n",
    "    top_features = SelectFromModel(model, threshold='mean').fit(X_train, y_train).get_support()\n",
    "    print(f\"\\nTop Features for {model_name}:\\n\", X_train.columns[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models:\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Cross-Validation Accuracy: {cross_val_scores.mean():.4f} (+/- {cross_val_scores.std():.4f})\")\n",
    "\n",
    "    # Testing\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Additional evaluation metrics (classification report)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6494c43",
   "metadata": {},
   "source": [
    "**Decision Tree:**\n",
    "Cross-Validation Accuracy: 62.00% (+/- 2.18)\n",
    "Test Accuracy: 62.50%\n",
    "Precision, recall, and F1-score are around 0.62 for both classes.\n",
    "\n",
    "**Random Forest:**\n",
    "Cross-Validation Accuracy: 64.75% (+/- 2.64)\n",
    "Test Accuracy: 69.50%\n",
    "Precision, recall, and F1-score are around 0.69 for both classes.\n",
    "\n",
    "**Gradient Boosting:**\n",
    "Cross-Validation Accuracy: 66.25% (+/- 1.31)\n",
    "Test Accuracy: 71.50%\n",
    "Precision, recall, and F1-score are around 0.71 for both classes.\n",
    "\n",
    "**Logistic Regression:*\n",
    "Cross-Validation Accuracy: 62.88% (+/- 1.88)\n",
    "Test Accuracy: 63.00%\n",
    "Precision, recall, and F1-score are around 0.63 for both classes.\n",
    "\n",
    "**Support Vector Machine:**\n",
    "Cross-Validation Accuracy: 63.75% (+/- 1.37)\n",
    "Test Accuracy: 64.50%\n",
    "Precision, recall, and F1-score are around 0.64 for both classes.\n",
    "\n",
    "**Observations:**\n",
    "Random Forest, Gradient Boosting, and Support Vector Machine show good performance, with accuracy above 65%.\n",
    "Gradient Boosting has the highest test accuracy at 71.50%.\n",
    "The models appear to be balanced, with similar precision, recall, and F1-scores for both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb3ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92154bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
